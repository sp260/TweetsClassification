{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4998 entries, 0 to 4997\n",
      "Data columns (total 4 columns):\n",
      "Id           4998 non-null object\n",
      "Sentiment    4998 non-null object\n",
      "Group        4998 non-null object\n",
      "Tweet        4998 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import pickle\n",
    "import codecs\n",
    "import spacy\n",
    "import glob\n",
    "import re\n",
    "\n",
    "all_files = glob.glob(\"/corpus/groupe*.txt\")\n",
    "df = pd.DataFrame()\n",
    "for file_ in all_files: \n",
    "    list_of_lists = []\n",
    "    with open(file_, 'rU') as f:\n",
    "        for line in f:\n",
    "            tweet = ' '.join(line.split(\")\")[1:])\n",
    "            id = line.split(\")\")[0].split(\",\")[0][1:]\n",
    "            sentiment = line.split(\")\")[0].split(\",\")[1]\n",
    "            try:\n",
    "                group = line.split(\")\")[0].split(\",\")[2]\n",
    "            except:\n",
    "                group = ''\n",
    "            list_of_lists.append([id, sentiment, group, tweet])\n",
    "    next_df = pd.DataFrame(list_of_lists, columns=['Id','Sentiment', 'Group', 'Tweet'])\n",
    "    df = df.append(next_df)\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    2507\n",
      "neu    1744\n",
      "irr    385 \n",
      "pos    362 \n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"gÃ´che\": \"gauche\",\n",
    "    \"gauchos\": \"gauche\",\n",
    "    \"rÃ©ac\": \"rÃ©action\",\n",
    "    \"co\": \"companie\",\n",
    "    \"cie\": \"companie\",\n",
    "    \"and\": \"et\",\n",
    "    \"but\": \"mais\",\n",
    "    \"ui\": \"oui\",\n",
    "    \"@macron\": \"Macron\",\n",
    "    \"@EmmanuelMacron\": \"Emmanuel Macron\",\n",
    "    \"GJ\": \"gilet jaune\",\n",
    "    \" 1 \": \" un \",\n",
    "    \"PR\": \"prÃ©sident\",\n",
    "    \"RT\": \"retweet\",\n",
    "    \"LREM\": \"la rÃ©publique en marche\",\n",
    "    \"LAREM\": \"la rÃ©publique en marche\",\n",
    "    \"#LREM\": \"la rÃ©publique en marche\",\n",
    "    \"#LAREM\": \"la rÃ©publique en marche\",\n",
    "    \"telma\": \"tellement\",\n",
    "    \"ctr\": \"contre\",\n",
    "    \"5e\": \"cinquieme\",\n",
    "    \"foute\": \"foutre\",\n",
    "    \"my god\": \"mon dieu\",\n",
    "    \"nn\": \"non\",\n",
    "    \"b8en\": \"bien\",\n",
    "    \"good\": \"bien\",\n",
    "    \"bad\": \"mauvais\",\n",
    "    \"lui\": \"il\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr')\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    decoded = str(text)\n",
    "    apostrophe_handled = re.sub(\"â€™\", \"'\", decoded)\n",
    "    expanded = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in apostrophe_handled.split(\" \")])\n",
    "    parsed = nlp(expanded)\n",
    "    final_tokens = []\n",
    "    for t in parsed:\n",
    "        if t.is_punct or t.is_space or t.like_num or t.like_url or str(t).startswith('@'):\n",
    "            pass\n",
    "        else:\n",
    "            if t.lemma_ == '-PRON-':\n",
    "                final_tokens.append(str(t))\n",
    "            else:\n",
    "                sc_removed = re.sub(\"[^a-zA-ZÃ©Ã¨ÃªÃ¹Ã»Ã Ã¢Å“Ã§Ã®]\", '', str(t.lemma_))\n",
    "                if len(sc_removed) > 1:\n",
    "                    final_tokens.append(sc_removed)\n",
    "    joined = ' '.join(final_tokens)\n",
    "    spell_corrected = re.sub(r'(.)\\1+', r'\\1\\1', joined)\n",
    "    return spell_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131     ðŸ˜‚ ðŸ˜‚ ðŸ˜‚ #Macron n'a peur de rien Il vit dans son monde... Le dialogue est inutile... https://t.co/mT9GBDM59D\\n                                                                                                                          \n",
      "132     macron ne reconnait pas une personne comme un Ãªtre humain Ã  qui l'on doit le respect jusque dans la mort assassinÃ©e par sa police https://t.co/o7vKzXWQxe\\n                                                                           \n",
      "133     @PublicsenatPro @publicsenat @MartinGenier @fitouss J'ai vu Ã  la tÃ©lÃ© le Roi Jupiter #Macron houlala il est bien en campagne pour les EuropÃ©en ðŸ¤¨ https://t.co/QLpa4BEj8x\\n                                                            \n",
      "134     #algÃ©rie ILS SONT INDEPENDANTS NOUS N AVONS PAS A INTERVENIR CONTRAIREMENT A CE QU A FAIT #macron AU VENEZUELA AUX ALGERIENS DE GERER A Paris, des AlgÃ©riens partagÃ©s sur un rÃ´le de la France dans la crise https://t.co/hcCGz4tfdG\\n\n",
      "Name: Tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(df.Tweet[131:135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Macron ne avoir peur de rien il voir dan son monde le dialogue Ãªtre inutile', 'macron ne reconner pas un personne comme Ãªtre humain qui le on devoir le respect jusqu dan le mort assassiner par son police', 'il avoir voir le tÃ©lÃ© le Roi Jupiter Macron houlala il Ãªtre bien en campagne pour le europÃ©en', 'algÃ©rie il Ãªtre independant nous ne avoir pas INTERVENIR contrairement ce que avoir faire macron au venezuela AUX algerien DE gerer avoir Paris un algÃ©rien partagÃ© sur rle de le France dan le crise']\n"
     ]
    }
   ],
   "source": [
    "print([tweet_cleaner(t) for t in df.Tweet[131:135]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_tweet'] = [tweet_cleaner(t) for t in df.Tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Group</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102616518876168193</td>\n",
       "      <td>neu</td>\n",
       "      <td>Groupe9</td>\n",
       "      <td>Emmanuel #Macron a dÃ©cidÃ© de prendre une sorte de leadership europÃ©en. Il lui reste maintenant Ã  le dÃ©montrer et c'est loin d'Ãªtre gagnÃ© quand on voit les revers qu'a pu essuyer la #France cette semaine, je pense d'abord Ã  #AirFranceKLM. @JeudyBruno #Europe #cdanslair https://t.co/9LhQ9XNOi3\\n</td>\n",
       "      <td>Emmanuel Macron avoir dÃ©cider de prendre un sorte de leadership europÃ©en il luire rester maintenant le dÃ©montrer et ce Ãªtre loin de Ãªtre gagner quand on voir le revers que avoir pouvoir essuyer le France ce semaine il penser de abord airfranceklm Europe cdanslair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102616470125793281</td>\n",
       "      <td>neu</td>\n",
       "      <td>Groupe9</td>\n",
       "      <td>Grand dÃ©bat national : Emmanuel Macron se rendra dans les Alpes-de-Haute-Provence jeudi https://t.co/WMuciXR82L\\n</td>\n",
       "      <td>grand dÃ©bat national Emmanuel Macron se rendre dan le alpesdehauteprovence jeudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102616467764260864</td>\n",
       "      <td>neu</td>\n",
       "      <td>Groupe9</td>\n",
       "      <td>Emmanuel Macron lance une Â«Â acadÃ©mieÂ Â» europÃ©enneÂ du renseignement https://t.co/RjJRsvO700 https://t.co/eF2W3epcWB\\n</td>\n",
       "      <td>Emmanuel Macron lancer un acadÃ©mie europÃ©en du renseignement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102616455877668864</td>\n",
       "      <td>neg</td>\n",
       "      <td>Groupe9</td>\n",
       "      <td>@BrunoPaumard ben si tes comptes 1 et 2 ont Ã©tÃ© bloquÃ©s c'est que t'as fait le con ,ou alors tu sais pas compter jusqu'Ã  1 ! bon laisse tomber ton gilet jaune vomis et convertis toi vers Macron ton prÃ©sident tu feras plus ta jaunisse tu te sentiras mieux dans ton froc ! https://t.co/O8zPqKryAj\\n</td>\n",
       "      <td>ben si compte et avoir Ãªtre bloquer ce Ãªtre que avoir faire le con ou alors tu savoir pas compter jusque bon laisser tomber ton gilet jaune vomir et convertir lui ver Macron ton prÃ©sident tu faire plus ton jaunisse tu se sentira mieux dan ton froc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102616439222079490</td>\n",
       "      <td>neu</td>\n",
       "      <td>Groupe9</td>\n",
       "      <td>Emmanuel Macron lance une Â«Â acadÃ©mieÂ Â» europÃ©enneÂ du renseignement https://t.co/P5V8eiFJJV\\n</td>\n",
       "      <td>Emmanuel Macron lancer un acadÃ©mie europÃ©en du renseignement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id Sentiment    Group  \\\n",
       "0  1102616518876168193  neu       Groupe9   \n",
       "1  1102616470125793281  neu       Groupe9   \n",
       "2  1102616467764260864  neu       Groupe9   \n",
       "3  1102616455877668864  neg       Groupe9   \n",
       "4  1102616439222079490  neu       Groupe9   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                       Tweet  \\\n",
       "0   Emmanuel #Macron a dÃ©cidÃ© de prendre une sorte de leadership europÃ©en. Il lui reste maintenant Ã  le dÃ©montrer et c'est loin d'Ãªtre gagnÃ© quand on voit les revers qu'a pu essuyer la #France cette semaine, je pense d'abord Ã  #AirFranceKLM. @JeudyBruno #Europe #cdanslair https://t.co/9LhQ9XNOi3\\n     \n",
       "1   Grand dÃ©bat national : Emmanuel Macron se rendra dans les Alpes-de-Haute-Provence jeudi https://t.co/WMuciXR82L\\n                                                                                                                                                                                          \n",
       "2   Emmanuel Macron lance une Â«Â acadÃ©mieÂ Â» europÃ©enneÂ du renseignement https://t.co/RjJRsvO700 https://t.co/eF2W3epcWB\\n                                                                                                                                                                                       \n",
       "3   @BrunoPaumard ben si tes comptes 1 et 2 ont Ã©tÃ© bloquÃ©s c'est que t'as fait le con ,ou alors tu sais pas compter jusqu'Ã  1 ! bon laisse tomber ton gilet jaune vomis et convertis toi vers Macron ton prÃ©sident tu feras plus ta jaunisse tu te sentiras mieux dans ton froc ! https://t.co/O8zPqKryAj\\n   \n",
       "4   Emmanuel Macron lance une Â«Â acadÃ©mieÂ Â» europÃ©enneÂ du renseignement https://t.co/P5V8eiFJJV\\n                                                                                                                                                                                                               \n",
       "\n",
       "                                                                                                                                                                                                                                                               Clean_tweet  \n",
       "0  Emmanuel Macron avoir dÃ©cider de prendre un sorte de leadership europÃ©en il luire rester maintenant le dÃ©montrer et ce Ãªtre loin de Ãªtre gagner quand on voir le revers que avoir pouvoir essuyer le France ce semaine il penser de abord airfranceklm Europe cdanslair  \n",
       "1  grand dÃ©bat national Emmanuel Macron se rendre dan le alpesdehauteprovence jeudi                                                                                                                                                                                         \n",
       "2  Emmanuel Macron lancer un acadÃ©mie europÃ©en du renseignement                                                                                                                                                                                                             \n",
       "3  ben si compte et avoir Ãªtre bloquer ce Ãªtre que avoir faire le con ou alors tu savoir pas compter jusque bon laisser tomber ton gilet jaune vomir et convertir lui ver Macron ton prÃ©sident tu faire plus ton jaunisse tu se sentira mieux dan ton froc                  \n",
       "4  Emmanuel Macron lancer un acadÃ©mie europÃ©en du renseignement                                                                                                                                                                                                             "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get stopwords from file\n",
    "with open('./stop_words_fr.txt') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:624: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df.Clean_tweet.values\n",
    "y = df.Sentiment.values\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# split train & test\n",
    "training_X, test_X, training_y, test_y = train_test_split(X, y, test_size = .3, random_state=42)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_s, y_train_s = sm.fit_sample(training_X, training_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_s, y_train_s, test_size = .3, random_state=42)\n",
    "\n",
    "# model tuning & validation\n",
    "cv = StratifiedKFold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. n_estimators=100, total=   1.7s\n",
      "[CV] n_estimators=100 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. n_estimators=100, total=   0.3s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.3s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.6s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.5s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.5s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   0.6s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   0.6s\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] ................................. n_estimators=300, total=   0.6s\n",
      "[CV] n_estimators=400 ................................................\n",
      "[CV] ................................. n_estimators=400, total=   0.8s\n",
      "[CV] n_estimators=400 ................................................\n",
      "[CV] ................................. n_estimators=400, total=   0.7s\n",
      "[CV] n_estimators=400 ................................................\n",
      "[CV] ................................. n_estimators=400, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "{'n_estimators': 300}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         irr       0.17      0.16      0.17       111\n",
      "         neg       0.65      0.81      0.72       764\n",
      "         neu       0.72      0.45      0.55       526\n",
      "         pos       0.33      0.36      0.34        99\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1500\n",
      "   macro avg       0.47      0.45      0.45      1500\n",
      "weighted avg       0.62      0.61      0.60      1500\n",
      "\n",
      "Accuracy 0.6066666666666667\n"
     ]
    }
   ],
   "source": [
    "rf_grid = {  \n",
    "     #'max_depth': list(range(10,100,10)),\n",
    "     #'max_features': ['auto', 'sqrt'],\n",
    "     #'min_samples_leaf': [1, 2, 4],\n",
    "     #'min_samples_split': [2, 5, 10],\n",
    "     'n_estimators': list(range(100,500,100))\n",
    "}\n",
    "                  \n",
    "rf_clf = RandomForestClassifier(n_estimators=35, max_depth=8, min_samples_split=4,n_jobs=-1)\n",
    "\n",
    "best_rf_clf = GridSearchCV(rf_clf, rf_grid, verbose=2,cv=cv)\n",
    "best_rf_clf.fit(X_train, y_train)\n",
    "rf_preds = best_rf_clf.predict(test_X)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(best_rf_clf.best_params_)\n",
    "print(classification_report(test_y, rf_preds))\n",
    "print(\"Accuracy\", accuracy_score(test_y, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l1 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0001, penalty=l2 ............................................\n",
      "[CV] ............................. C=0.0001, penalty=l2, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l1 ............................\n",
      "[CV] ............. C=0.00026366508987303583, penalty=l1, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l1 ............................\n",
      "[CV] ............. C=0.00026366508987303583, penalty=l1, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l1 ............................\n",
      "[CV] ............. C=0.00026366508987303583, penalty=l1, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/sp/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sp/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............. C=0.00026366508987303583, penalty=l2, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l2 ............................\n",
      "[CV] ............. C=0.00026366508987303583, penalty=l2, total=   0.0s\n",
      "[CV] C=0.00026366508987303583, penalty=l2 ............................\n",
      "[CV] ............. C=0.00026366508987303583, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l1 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l1 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l1 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l2 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l2 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0006951927961775605, penalty=l2 .............................\n",
      "[CV] .............. C=0.0006951927961775605, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l1 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l1 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l1 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l2 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l2 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l2, total=   0.0s\n",
      "[CV] C=0.0018329807108324356, penalty=l2 .............................\n",
      "[CV] .............. C=0.0018329807108324356, penalty=l2, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l1 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l1, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l1 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l1, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l1 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l1, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l2 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l2, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l2 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l2, total=   0.0s\n",
      "[CV] C=0.004832930238571752, penalty=l2 ..............................\n",
      "[CV] ............... C=0.004832930238571752, penalty=l2, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l1 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l1, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l1 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l1, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l1 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l1, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l2 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l2, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l2 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l2, total=   0.0s\n",
      "[CV] C=0.012742749857031334, penalty=l2 ..............................\n",
      "[CV] ............... C=0.012742749857031334, penalty=l2, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l1 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l1, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l1 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l1, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l1 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l1, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l2 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l2, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l2 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l2, total=   0.0s\n",
      "[CV] C=0.03359818286283781, penalty=l2 ...............................\n",
      "[CV] ................ C=0.03359818286283781, penalty=l2, total=   0.0s\n",
      "[CV] C=0.08858667904100823, penalty=l1 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l1, total=   0.0s\n",
      "[CV] C=0.08858667904100823, penalty=l1 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l1, total=   0.0s\n",
      "[CV] C=0.08858667904100823, penalty=l1 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l1, total=   0.0s\n",
      "[CV] C=0.08858667904100823, penalty=l2 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l2, total=   0.0s\n",
      "[CV] C=0.08858667904100823, penalty=l2 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l2, total=   0.1s\n",
      "[CV] C=0.08858667904100823, penalty=l2 ...............................\n",
      "[CV] ................ C=0.08858667904100823, penalty=l2, total=   0.0s\n",
      "[CV] C=0.23357214690901212, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23357214690901212, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23357214690901212, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23357214690901212, penalty=l2 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l2, total=   0.1s\n",
      "[CV] C=0.23357214690901212, penalty=l2 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l2, total=   0.0s\n",
      "[CV] C=0.23357214690901212, penalty=l2 ...............................\n",
      "[CV] ................ C=0.23357214690901212, penalty=l2, total=   0.0s\n",
      "[CV] C=0.615848211066026, penalty=l1 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l1, total=   0.1s\n",
      "[CV] C=0.615848211066026, penalty=l1 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l1, total=   0.1s\n",
      "[CV] C=0.615848211066026, penalty=l1 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l1, total=   0.1s\n",
      "[CV] C=0.615848211066026, penalty=l2 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l2, total=   0.1s\n",
      "[CV] C=0.615848211066026, penalty=l2 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l2, total=   0.1s\n",
      "[CV] C=0.615848211066026, penalty=l2 .................................\n",
      "[CV] .................. C=0.615848211066026, penalty=l2, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l1 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l1, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l1 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l1, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l1 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l1, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l2 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l2, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l2 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l2, total=   0.1s\n",
      "[CV] C=1.623776739188721, penalty=l2 .................................\n",
      "[CV] .................. C=1.623776739188721, penalty=l2, total=   0.1s\n",
      "[CV] C=4.281332398719396, penalty=l1 .................................\n",
      "[CV] .................. C=4.281332398719396, penalty=l1, total=   0.2s\n",
      "[CV] C=4.281332398719396, penalty=l1 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=4.281332398719396, penalty=l1, total=   0.2s\n",
      "[CV] C=4.281332398719396, penalty=l1 .................................\n",
      "[CV] .................. C=4.281332398719396, penalty=l1, total=   0.2s\n",
      "[CV] C=4.281332398719396, penalty=l2 .................................\n",
      "[CV] .................. C=4.281332398719396, penalty=l2, total=   0.1s\n",
      "[CV] C=4.281332398719396, penalty=l2 .................................\n",
      "[CV] .................. C=4.281332398719396, penalty=l2, total=   0.1s\n",
      "[CV] C=4.281332398719396, penalty=l2 .................................\n",
      "[CV] .................. C=4.281332398719396, penalty=l2, total=   0.1s\n",
      "[CV] C=11.288378916846883, penalty=l1 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l1, total=   0.2s\n",
      "[CV] C=11.288378916846883, penalty=l1 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l1, total=   0.3s\n",
      "[CV] C=11.288378916846883, penalty=l1 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l1, total=   0.3s\n",
      "[CV] C=11.288378916846883, penalty=l2 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l2, total=   0.1s\n",
      "[CV] C=11.288378916846883, penalty=l2 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l2, total=   0.1s\n",
      "[CV] C=11.288378916846883, penalty=l2 ................................\n",
      "[CV] ................. C=11.288378916846883, penalty=l2, total=   0.1s\n",
      "[CV] C=29.763514416313132, penalty=l1 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l1, total=   0.3s\n",
      "[CV] C=29.763514416313132, penalty=l1 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l1, total=   0.3s\n",
      "[CV] C=29.763514416313132, penalty=l1 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l1, total=   0.4s\n",
      "[CV] C=29.763514416313132, penalty=l2 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l2, total=   0.1s\n",
      "[CV] C=29.763514416313132, penalty=l2 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l2, total=   0.1s\n",
      "[CV] C=29.763514416313132, penalty=l2 ................................\n",
      "[CV] ................. C=29.763514416313132, penalty=l2, total=   0.1s\n",
      "[CV] C=78.47599703514607, penalty=l1 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l1, total=   0.4s\n",
      "[CV] C=78.47599703514607, penalty=l1 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l1, total=   0.4s\n",
      "[CV] C=78.47599703514607, penalty=l1 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l1, total=   0.5s\n",
      "[CV] C=78.47599703514607, penalty=l2 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l2, total=   0.1s\n",
      "[CV] C=78.47599703514607, penalty=l2 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l2, total=   0.1s\n",
      "[CV] C=78.47599703514607, penalty=l2 .................................\n",
      "[CV] .................. C=78.47599703514607, penalty=l2, total=   0.1s\n",
      "[CV] C=206.913808111479, penalty=l1 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l1, total=   0.5s\n",
      "[CV] C=206.913808111479, penalty=l1 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l1, total=   0.5s\n",
      "[CV] C=206.913808111479, penalty=l1 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l1, total=   0.5s\n",
      "[CV] C=206.913808111479, penalty=l2 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l2, total=   0.1s\n",
      "[CV] C=206.913808111479, penalty=l2 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l2, total=   0.1s\n",
      "[CV] C=206.913808111479, penalty=l2 ..................................\n",
      "[CV] ................... C=206.913808111479, penalty=l2, total=   0.2s\n",
      "[CV] C=545.5594781168514, penalty=l1 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l1, total=   0.6s\n",
      "[CV] C=545.5594781168514, penalty=l1 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l1, total=   0.6s\n",
      "[CV] C=545.5594781168514, penalty=l1 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l1, total=   0.7s\n",
      "[CV] C=545.5594781168514, penalty=l2 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l2, total=   0.2s\n",
      "[CV] C=545.5594781168514, penalty=l2 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l2, total=   0.2s\n",
      "[CV] C=545.5594781168514, penalty=l2 .................................\n",
      "[CV] .................. C=545.5594781168514, penalty=l2, total=   0.2s\n",
      "[CV] C=1438.44988828766, penalty=l1 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l1, total=   0.7s\n",
      "[CV] C=1438.44988828766, penalty=l1 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l1, total=   0.5s\n",
      "[CV] C=1438.44988828766, penalty=l1 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l1, total=   0.6s\n",
      "[CV] C=1438.44988828766, penalty=l2 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l2, total=   0.2s\n",
      "[CV] C=1438.44988828766, penalty=l2 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l2, total=   0.3s\n",
      "[CV] C=1438.44988828766, penalty=l2 ..................................\n",
      "[CV] ................... C=1438.44988828766, penalty=l2, total=   0.2s\n",
      "[CV] C=3792.690190732246, penalty=l1 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l1, total=   0.5s\n",
      "[CV] C=3792.690190732246, penalty=l1 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l1, total=   0.5s\n",
      "[CV] C=3792.690190732246, penalty=l1 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l1, total=   0.4s\n",
      "[CV] C=3792.690190732246, penalty=l2 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l2, total=   0.2s\n",
      "[CV] C=3792.690190732246, penalty=l2 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l2, total=   0.2s\n",
      "[CV] C=3792.690190732246, penalty=l2 .................................\n",
      "[CV] .................. C=3792.690190732246, penalty=l2, total=   0.3s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.3s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.3s\n",
      "[CV] C=10000.0, penalty=l1 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l1, total=   0.3s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.2s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.2s\n",
      "[CV] C=10000.0, penalty=l2 ...........................................\n",
      "[CV] ............................ C=10000.0, penalty=l2, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{'C': 29.763514416313132, 'penalty': 'l2'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         irr       0.23      0.23      0.23       111\n",
      "         neg       0.70      0.69      0.70       764\n",
      "         neu       0.60      0.59      0.60       526\n",
      "         pos       0.28      0.33      0.30        99\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      1500\n",
      "   macro avg       0.45      0.46      0.46      1500\n",
      "weighted avg       0.60      0.60      0.60      1500\n",
      "\n",
      "Accuracy 0.5993333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_grid = {\n",
    "    \"C\": np.logspace(-4,4,20), \n",
    "    \"penalty\": [\"l1\",\"l2\"] # l1 lasso l2 ridge\n",
    "}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "best_lr_clf = GridSearchCV(lr_clf, lr_grid, verbose=2,cv=cv)\n",
    "best_lr_clf.fit(X_train, y_train)\n",
    "lr_preds = best_lr_clf.predict(test_X)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(best_lr_clf.best_params_)\n",
    "print(classification_report(test_y, lr_preds))\n",
    "print(\"Accuracy\", accuracy_score(test_y, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rf classifier to a file\n",
    "save_classifier = open(\"rf_classifier.pickle\", 'wb')\n",
    "pickle.dump(best_rf_clf, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "# Save lr classifier to a file\n",
    "save_classifier = open(\"lr_classifier.pickle\", 'wb')\n",
    "pickle.dump(best_lr_clf, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the saved file and uplaod it to an object\n",
    "vec = open(\"rf_classifier.pickle\", 'rb')\n",
    "rf_clf = pickle.load(vec)\n",
    "vec.close()\n",
    "\n",
    "# Retrieve the saved file and uplaod it to an object\n",
    "vec = open(\"lr_classifier.pickle\", 'rb')\n",
    "lr_clf = pickle.load(vec)\n",
    "vec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aimer</th>\n",
       "      <th>avoir</th>\n",
       "      <th>bien</th>\n",
       "      <th>bon</th>\n",
       "      <th>ce</th>\n",
       "      <th>comme</th>\n",
       "      <th>emmanuel</th>\n",
       "      <th>etre</th>\n",
       "      <th>il</th>\n",
       "      <th>macron</th>\n",
       "      <th>mauvais</th>\n",
       "      <th>merde</th>\n",
       "      <th>monstre</th>\n",
       "      <th>sale</th>\n",
       "      <th>un</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.409430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321974</td>\n",
       "      <td>0.387878</td>\n",
       "      <td>0.229087</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507806</td>\n",
       "      <td>0.507806</td>\n",
       "      <td>0.507806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409694</td>\n",
       "      <td>0.241972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.179535</td>\n",
       "      <td>0.179535</td>\n",
       "      <td>0.179535</td>\n",
       "      <td>0.395209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395209</td>\n",
       "      <td>0.264676</td>\n",
       "      <td>0.144848</td>\n",
       "      <td>0.273868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      aimer     avoir      bien       bon        ce     comme  emmanuel  \\\n",
       "0  0.000000  0.000000  0.000000  0.611353  0.000000  0.000000  0.611353   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.480764  0.480764  0.000000   \n",
       "4  0.507806  0.507806  0.507806  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.179535  0.179535  0.179535  0.395209  0.000000  0.000000  0.395209   \n",
       "\n",
       "       etre        il    macron   mauvais     merde   monstre      sale  \\\n",
       "0  0.409430  0.000000  0.291313  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.409430  0.000000  0.291313  0.000000  0.000000  0.611353  0.000000   \n",
       "2  0.000000  0.000000  0.319302  0.000000  0.670092  0.000000  0.670092   \n",
       "3  0.321974  0.387878  0.229087  0.480764  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.409694  0.241972  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.264676  0.144848  0.273868  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         un  \n",
       "0  0.000000  \n",
       "1  0.611353  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of oversamling with SMOTE\n",
    "\n",
    "sent1 = \"emmanuel macron etre bon\"\n",
    "sent2 = \"macron etre un monstre\"\n",
    "sent3 = \"macron sale merde\"\n",
    "sent4 = \"comme il etre mauvais ce macron\"\n",
    "sent5 = \"il avoir bien aimer macron\"\n",
    "\n",
    "testing_text = pd.Series([sent1, sent2, sent3, sent4, sent5])\n",
    "testing_target = pd.Series([1,0,0,0,1])\n",
    "\n",
    "tv = TfidfVectorizer(stop_words=None, max_features=100000)\n",
    "testing_tfidf = tv.fit_transform(testing_text)\n",
    "\n",
    "smt = SMOTE(random_state=777, k_neighbors=1)\n",
    "X_SMOTE, y_SMOTE = smt.fit_sample(testing_tfidf, testing_target)\n",
    "df_topredict = pd.DataFrame(X_SMOTE.todense(), columns=tv.get_feature_names())\n",
    "df_topredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Columns: 10332 entries, aah to Å“uvre\n",
      "dtypes: float64(10332)\n",
      "memory usage: 118.2 MB\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_X.todense(), columns=vectorizer.get_feature_names()).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df = pd.DataFrame(0.0, index=np.arange(len(X_SMOTE.todense())), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_topredict:\n",
    "    if column in vectorizer.get_feature_names():\n",
    "        container_df[column] = df_topredict[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neu', 'neg', 'neu', 'pos', 'neu', 'neu'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = best_lr_clf.predict(container_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neu', 'neu', 'neg', 'neg', 'neg', 'neu'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = best_rf_clf.predict(container_df)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
